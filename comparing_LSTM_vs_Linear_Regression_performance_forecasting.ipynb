{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1T1qh0LovN6flcfHl7wL4RtRpcV3D0ATi",
      "authorship_tag": "ABX9TyMjh1H9csvaLbHVnsVsb2mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brockgion/brockgion.github.io/blob/master/comparing_LSTM_vs_Linear_Regression_performance_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoaJxzbNHWen",
        "outputId": "9c1741d5-5531-478d-d5bd-468b4089aa03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Libraries loaded successfully!\n",
            "Pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Master's Thesis: Household Load Forecasting with LSTM\n",
        "# Data Loading and Setup\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries loaded successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base path and month folders (NOTE: THIS WILL ONLY WORK IF LOGGED INTO GOOGLE DRIVE ACCT)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikl_1hp4MBzG",
        "outputId": "51550468-a02d-4e6b-9b0e-4997374184f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/pt1\"\n",
        "\n",
        "month_folders = [\n",
        "    \"November 2024\",\n",
        "    \"December 2024\",\n",
        "    \"January 2025\",\n",
        "    \"February 2025\",\n",
        "    \"March 2025\",\n",
        "    \"April 2025\",\n",
        "    \"May 2025\",\n",
        "    \"June 2025\",\n",
        "    \"July 2025\",\n",
        "    \"August 2025\",\n",
        "    \"September 2025\",\n",
        "    \"October 2025\"\n",
        "]\n",
        "\n",
        "# Function to load a single month's 15MIN data\n",
        "def load_month_data(month_folder):\n",
        "    month_path = os.path.join(base_path, month_folder)\n",
        "    search_pattern = os.path.join(month_path, \"*\", \"*15MIN.csv\")\n",
        "    files = glob.glob(search_pattern)\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(f\"⚠️  WARNING: No 15MIN file found in {month_folder}\")\n",
        "        return None\n",
        "\n",
        "    filepath = files[0]\n",
        "    print(f\"✓ Loading: {month_folder}\")\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['source_month'] = month_folder\n",
        "    return df\n",
        "\n",
        "# Load all months\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING DATA FROM ALL MONTHS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_data = []\n",
        "for month in month_folders:\n",
        "    month_df = load_month_data(month)\n",
        "    if month_df is not None:\n",
        "        all_data.append(month_df)\n",
        "        print(f\"  → Loaded {len(month_df):,} rows\")\n",
        "\n",
        "print(f\"\\n✓ Successfully loaded {len(all_data)} months of data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLBEqlnzJGfY",
        "outputId": "2613f7c1-6e23-4257-e058-84715e6fff1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LOADING DATA FROM ALL MONTHS\n",
            "============================================================\n",
            "✓ Loading: November 2024\n",
            "  → Loaded 2,411 rows\n",
            "✓ Loading: December 2024\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: January 2025\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: February 2025\n",
            "  → Loaded 2,689 rows\n",
            "✓ Loading: March 2025\n",
            "  → Loaded 2,973 rows\n",
            "✓ Loading: April 2025\n",
            "  → Loaded 2,881 rows\n",
            "✓ Loading: May 2025\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: June 2025\n",
            "  → Loaded 2,881 rows\n",
            "✓ Loading: July 2025\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: August 2025\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: September 2025\n",
            "  → Loaded 2,881 rows\n",
            "✓ Loading: October 2025\n",
            "  → Loaded 2,977 rows\n",
            "\n",
            "✓ Successfully loaded 12 months of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all months\n",
        "print(\"Combining all monthly data...\")\n",
        "df_combined = pd.concat(all_data, ignore_index=True)\n",
        "print(f\"✓ Combined shape: {df_combined.shape}\")\n",
        "\n",
        "# Parse timestamp and sort\n",
        "print(\"\\nCreating features...\")\n",
        "df_combined['timestamp'] = pd.to_datetime(df_combined['Time Bucket (America/Chicago)'])\n",
        "df_combined = df_combined.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "# Create total household power (TARGET variable)\n",
        "df_combined['total_power_kw'] = (\n",
        "    df_combined['SWORDFISH VUE-Mains_A (kWatts)'] +\n",
        "    df_combined['SWORDFISH VUE-Mains_B (kWatts)']\n",
        ")\n",
        "\n",
        "# Create time-based features\n",
        "df_combined['hour'] = df_combined['timestamp'].dt.hour\n",
        "df_combined['day_of_week'] = df_combined['timestamp'].dt.dayofweek\n",
        "df_combined['month'] = df_combined['timestamp'].dt.month\n",
        "df_combined['is_weekend'] = (df_combined['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "# Set timestamp as index\n",
        "df_combined = df_combined.set_index('timestamp')\n",
        "\n",
        "print(f\"✓ Date range: {df_combined.index[0]} to {df_combined.index[-1]}\")\n",
        "print(f\"✓ Power statistics:\")\n",
        "print(f\"   Mean: {df_combined['total_power_kw'].mean():.3f} kW\")\n",
        "print(f\"   Min:  {df_combined['total_power_kw'].min():.3f} kW\")\n",
        "print(f\"   Max:  {df_combined['total_power_kw'].max():.3f} kW\")\n",
        "print(f\"\\n✓ Features created: total_power_kw, hour, day_of_week, month, is_weekend\")\n",
        "print(f\"✓ Final shape: {df_combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qaY1EvMaQe",
        "outputId": "21b06a92-a812-4a9b-bf9a-e7ece1724265"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining all monthly data...\n",
            "✓ Combined shape: (34578, 23)\n",
            "\n",
            "Creating features...\n",
            "✓ Date range: 2024-11-07 13:30:00 to 2025-11-01 00:00:00\n",
            "✓ Power statistics:\n",
            "   Mean: 1.033 kW\n",
            "   Min:  0.079 kW\n",
            "   Max:  13.322 kW\n",
            "\n",
            "✓ Features created: total_power_kw, hour, day_of_week, month, is_weekend\n",
            "✓ Final shape: (34578, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split (80% train, 20% test)\n",
        "print(\"Creating train/test split...\")\n",
        "\n",
        "split_idx = int(len(df_combined) * 0.8)\n",
        "train_data = df_combined.iloc[:split_idx].copy()\n",
        "test_data = df_combined.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"\\n✓ Training Set: {len(train_data):,} rows\")\n",
        "print(f\"   Date range: {train_data.index[0]} to {train_data.index[-1]}\")\n",
        "print(f\"\\n✓ Test Set: {len(test_data):,} rows\")\n",
        "print(f\"   Date range: {test_data.index[0]} to {test_data.index[-1]}\")\n",
        "print(f\"\\n✓ Split verification: {'PASS' if train_data.index[-1] < test_data.index[0] else 'FAIL'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxV08VKXMgr8",
        "outputId": "df3ae9eb-8b62-4542-bb46-2eae56ebc05b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train/test split...\n",
            "\n",
            "✓ Training Set: 27,662 rows\n",
            "   Date range: 2024-11-07 13:30:00 to 2025-08-20 23:30:00\n",
            "\n",
            "✓ Test Set: 6,916 rows\n",
            "   Date range: 2025-08-20 23:45:00 to 2025-11-01 00:00:00\n",
            "\n",
            "✓ Split verification: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Linear Regression Baseline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "print(\"Building Linear Regression Baseline...\\n\")\n",
        "\n",
        "# Define features and target\n",
        "feature_cols = ['hour', 'day_of_week', 'month', 'is_weekend']\n",
        "target_col = 'total_power_kw'\n",
        "\n",
        "X_train = train_data[feature_cols]\n",
        "y_train = train_data[target_col]\n",
        "X_test = test_data[feature_cols]\n",
        "y_test = test_data[target_col]\n",
        "\n",
        "# Train model\n",
        "print(\"Training Linear Regression...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "print(\"✓ Model trained!\\n\")\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LINEAR REGRESSION BASELINE RESULTS (Table 2)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"   RMSE: {test_rmse:.4f} kW\")\n",
        "print(f\"   MAE:  {test_mae:.4f} kW\")\n",
        "print(f\"   MAPE: {test_mape:.2f}%\")\n",
        "print(f\"   R²:   {test_r2:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Store for comparison\n",
        "baseline_results = {\n",
        "    'Model': 'Linear Regression',\n",
        "    'RMSE': test_rmse,\n",
        "    'MAE': test_mae,\n",
        "    'MAPE': test_mape,\n",
        "    'R2': test_r2\n",
        "}\n",
        "\n",
        "print(\"\\n✓ Baseline complete! Ready for LSTM comparison.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BnxUg9kMm9r",
        "outputId": "1258a0a1-e393-4232-c731-18106f68f4c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Linear Regression Baseline...\n",
            "\n",
            "Training Linear Regression...\n",
            "✓ Model trained!\n",
            "\n",
            "============================================================\n",
            "LINEAR REGRESSION BASELINE RESULTS (Table 2)\n",
            "============================================================\n",
            "   RMSE: 0.9376 kW\n",
            "   MAE:  0.5777 kW\n",
            "   MAPE: 65.30%\n",
            "   R²:   0.0439\n",
            "============================================================\n",
            "\n",
            "✓ Baseline complete! Ready for LSTM comparison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Long Short-Term Memory (LSTM) MODEL\n",
        "# ============================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "print(\"Building LSTM Model...\\n\")\n",
        "\n",
        "# Step 1: Create sequences (use past 24 hours to predict next value)\n",
        "print(\"Step 1: Creating sequences...\")\n",
        "lookback = 96  # 24 hours * 4 (15-min intervals)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data[['total_power_kw']])\n",
        "test_scaled = scaler.transform(test_data[['total_power_kw']])\n",
        "\n",
        "def create_sequences(data, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i+lookback])\n",
        "        y.append(data[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "print(f\"   Training sequences: {X_train.shape}\")\n",
        "print(f\"   Test sequences: {X_test.shape}\")\n",
        "\n",
        "# Step 2: Build LSTM architecture\n",
        "print(\"\\nStep 2: Building LSTM model...\")\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "print(\"   ✓ Model architecture created\")\n",
        "\n",
        "# Step 3: Train model\n",
        "print(\"\\nStep 3: Training LSTM (this takes 5-10 minutes)...\\n\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Is6cfH4Ms2h",
        "outputId": "838d9eaa-d706-4ac4-ef38-6199b5e8d1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building LSTM Model...\n",
            "\n",
            "Step 1: Creating sequences...\n",
            "   Training sequences: (27566, 96, 1)\n",
            "   Test sequences: (6820, 96, 1)\n",
            "\n",
            "Step 2: Building LSTM model...\n",
            "   ✓ Model architecture created\n",
            "\n",
            "Step 3: Training LSTM (this takes 5-10 minutes)...\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 106ms/step - loss: 0.0095 - mae: 0.0532 - val_loss: 0.0052 - val_mae: 0.0399\n",
            "Epoch 2/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 102ms/step - loss: 0.0078 - mae: 0.0480 - val_loss: 0.0049 - val_mae: 0.0355\n",
            "Epoch 3/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 101ms/step - loss: 0.0069 - mae: 0.0443 - val_loss: 0.0045 - val_mae: 0.0351\n",
            "Epoch 4/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 101ms/step - loss: 0.0071 - mae: 0.0447 - val_loss: 0.0046 - val_mae: 0.0339\n",
            "Epoch 5/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 98ms/step - loss: 0.0069 - mae: 0.0441 - val_loss: 0.0049 - val_mae: 0.0344\n",
            "Epoch 6/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 101ms/step - loss: 0.0067 - mae: 0.0427 - val_loss: 0.0043 - val_mae: 0.0333\n",
            "Epoch 7/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 100ms/step - loss: 0.0063 - mae: 0.0414 - val_loss: 0.0047 - val_mae: 0.0337\n",
            "Epoch 8/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 101ms/step - loss: 0.0068 - mae: 0.0427 - val_loss: 0.0045 - val_mae: 0.0337\n",
            "Epoch 9/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 108ms/step - loss: 0.0064 - mae: 0.0417 - val_loss: 0.0044 - val_mae: 0.0332\n",
            "Epoch 10/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0428 - val_loss: 0.0044 - val_mae: 0.0348\n",
            "Epoch 11/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 99ms/step - loss: 0.0062 - mae: 0.0409 - val_loss: 0.0044 - val_mae: 0.0334\n",
            "Epoch 12/20\n",
            "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 101ms/step - loss: 0.0067 - mae: 0.0426 - val_loss: 0.0044 - val_mae: 0.0328\n",
            "Epoch 13/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYuy29dYKNgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}