{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1T1qh0LovN6flcfHl7wL4RtRpcV3D0ATi",
      "authorship_tag": "ABX9TyNxotVO/6Pov3ZDvy8DvU0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brockgion/brockgion.github.io/blob/master/ITERATION2_(SEASONAL_SUMMER_3_MONTHS)_comparing_LSTM_vs_Linear_Regression_performance_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoaJxzbNHWen",
        "outputId": "c26e5a66-33f2-4cf9-d8bb-15b63295af93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Libraries loaded successfully!\n",
            "Pandas version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Electricity Household Load Forecasting with LSTM\n",
        "# Data Loading and Setup\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries loaded successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base path and month folders (NOTE: THIS WILL ONLY WORK IF LOGGED INTO GOOGLE DRIVE ACCT)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikl_1hp4MBzG",
        "outputId": "2373ef3f-4924-4d43-be07-a39ad7094896"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/pt1\"\n",
        "\n",
        "month_folders = [\n",
        "    # \"November 2024\",\n",
        "    # \"December 2024\",\n",
        "    # \"January 2025\",\n",
        "    # \"February 2025\",\n",
        "    # \"March 2025\",\n",
        "    # \"April 2025\",\n",
        "    # \"May 2025\",\n",
        "    \"June 2025\",\n",
        "    \"July 2025\",\n",
        "    \"August 2025\",\n",
        "    # \"September 2025\",\n",
        "    # \"October 2025\"\n",
        "]\n",
        "\n",
        "# Function to load a single month's 15MIN data\n",
        "def load_month_data(month_folder):\n",
        "    month_path = os.path.join(base_path, month_folder)\n",
        "    search_pattern = os.path.join(month_path, \"*\", \"*15MIN.csv\")\n",
        "    files = glob.glob(search_pattern)\n",
        "\n",
        "    if len(files) == 0:\n",
        "        print(f\"⚠️  WARNING: No 15MIN file found in {month_folder}\")\n",
        "        return None\n",
        "\n",
        "    filepath = files[0]\n",
        "    print(f\"✓ Loading: {month_folder}\")\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['source_month'] = month_folder\n",
        "    return df\n",
        "\n",
        "# Load all months\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING DATA FROM ALL MONTHS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_data = []\n",
        "for month in month_folders:\n",
        "    month_df = load_month_data(month)\n",
        "    if month_df is not None:\n",
        "        all_data.append(month_df)\n",
        "        print(f\"  → Loaded {len(month_df):,} rows\")\n",
        "\n",
        "print(f\"\\n✓ Successfully loaded {len(all_data)} months of data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLBEqlnzJGfY",
        "outputId": "05ff9d8f-4250-4787-c0fc-be2b2b53c99f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LOADING DATA FROM ALL MONTHS\n",
            "============================================================\n",
            "✓ Loading: June 2025\n",
            "  → Loaded 2,881 rows\n",
            "✓ Loading: July 2025\n",
            "  → Loaded 2,977 rows\n",
            "✓ Loading: August 2025\n",
            "  → Loaded 2,977 rows\n",
            "\n",
            "✓ Successfully loaded 3 months of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all months\n",
        "print(\"Combining all monthly data...\")\n",
        "df_combined = pd.concat(all_data, ignore_index=True)\n",
        "print(f\"✓ Combined shape: {df_combined.shape}\")\n",
        "\n",
        "# Parse timestamp and sort\n",
        "print(\"\\nCreating features...\")\n",
        "df_combined['timestamp'] = pd.to_datetime(df_combined['Time Bucket (America/Chicago)'])\n",
        "df_combined = df_combined.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "# Create total household power (TARGET variable)\n",
        "df_combined['total_power_kw'] = (\n",
        "    df_combined['SWORDFISH VUE-Mains_A (kWatts)'] +\n",
        "    df_combined['SWORDFISH VUE-Mains_B (kWatts)']\n",
        ")\n",
        "\n",
        "# Create time-based features\n",
        "df_combined['hour'] = df_combined['timestamp'].dt.hour\n",
        "df_combined['day_of_week'] = df_combined['timestamp'].dt.dayofweek\n",
        "df_combined['month'] = df_combined['timestamp'].dt.month\n",
        "df_combined['is_weekend'] = (df_combined['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "# Set timestamp as index\n",
        "df_combined = df_combined.set_index('timestamp')\n",
        "\n",
        "print(f\"✓ Date range: {df_combined.index[0]} to {df_combined.index[-1]}\")\n",
        "print(f\"✓ Power statistics:\")\n",
        "print(f\"   Mean: {df_combined['total_power_kw'].mean():.3f} kW\")\n",
        "print(f\"   Min:  {df_combined['total_power_kw'].min():.3f} kW\")\n",
        "print(f\"   Max:  {df_combined['total_power_kw'].max():.3f} kW\")\n",
        "print(f\"\\n✓ Features created: total_power_kw, hour, day_of_week, month, is_weekend\")\n",
        "print(f\"✓ Final shape: {df_combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qaY1EvMaQe",
        "outputId": "ddc7f561-3480-46ff-c588-a2a309af2a52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining all monthly data...\n",
            "✓ Combined shape: (8835, 21)\n",
            "\n",
            "Creating features...\n",
            "✓ Date range: 2025-06-01 00:00:00 to 2025-09-01 00:00:00\n",
            "✓ Power statistics:\n",
            "   Mean: 1.185 kW\n",
            "   Min:  0.285 kW\n",
            "   Max:  10.781 kW\n",
            "\n",
            "✓ Features created: total_power_kw, hour, day_of_week, month, is_weekend\n",
            "✓ Final shape: (8835, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train/test split (80% train, 20% test)\n",
        "print(\"Creating train/test split...\")\n",
        "\n",
        "split_idx = int(len(df_combined) * 0.8)\n",
        "train_data = df_combined.iloc[:split_idx].copy()\n",
        "test_data = df_combined.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"\\n✓ Training Set: {len(train_data):,} rows\")\n",
        "print(f\"   Date range: {train_data.index[0]} to {train_data.index[-1]}\")\n",
        "print(f\"\\n✓ Test Set: {len(test_data):,} rows\")\n",
        "print(f\"   Date range: {test_data.index[0]} to {test_data.index[-1]}\")\n",
        "print(f\"\\n✓ Split verification: {'PASS' if train_data.index[-1] < test_data.index[0] else 'FAIL'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxV08VKXMgr8",
        "outputId": "4f86eb24-fe93-4e74-8e4f-2677d2d9c2a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train/test split...\n",
            "\n",
            "✓ Training Set: 7,068 rows\n",
            "   Date range: 2025-06-01 00:00:00 to 2025-08-13 14:15:00\n",
            "\n",
            "✓ Test Set: 1,767 rows\n",
            "   Date range: 2025-08-13 14:30:00 to 2025-09-01 00:00:00\n",
            "\n",
            "✓ Split verification: PASS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Linear Regression MODEL\n",
        "# ============================================================\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "print(\"Building Linear Regression Baseline...\\n\")\n",
        "\n",
        "# Define features and target\n",
        "feature_cols = ['hour', 'day_of_week', 'month', 'is_weekend']\n",
        "target_col = 'total_power_kw'\n",
        "\n",
        "X_train = train_data[feature_cols]\n",
        "y_train = train_data[target_col]\n",
        "X_test = test_data[feature_cols]\n",
        "y_test = test_data[target_col]\n",
        "\n",
        "# Train model\n",
        "print(\"Training Linear Regression...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "print(\"✓ Model trained!\\n\")\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "test_mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LINEAR REGRESSION BASELINE RESULTS (Table 2)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"   RMSE: {test_rmse:.4f} kW\")\n",
        "print(f\"   MAE:  {test_mae:.4f} kW\")\n",
        "print(f\"   MAPE: {test_mape:.2f}%\")\n",
        "print(f\"   R²:   {test_r2:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Store for comparison\n",
        "baseline_results = {\n",
        "    'Model': 'Linear Regression',\n",
        "    'RMSE': test_rmse,\n",
        "    'MAE': test_mae,\n",
        "    'MAPE': test_mape,\n",
        "    'R2': test_r2\n",
        "}\n",
        "\n",
        "print(\"\\n✓ Baseline complete! Ready for LSTM comparison.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BnxUg9kMm9r",
        "outputId": "30fc8b90-1425-4a0a-9df5-d163e3353497"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Linear Regression Baseline...\n",
            "\n",
            "Training Linear Regression...\n",
            "✓ Model trained!\n",
            "\n",
            "============================================================\n",
            "LINEAR REGRESSION BASELINE RESULTS (Table 2)\n",
            "============================================================\n",
            "   RMSE: 0.9669 kW\n",
            "   MAE:  0.6542 kW\n",
            "   MAPE: 58.58%\n",
            "   R²:   0.0625\n",
            "============================================================\n",
            "\n",
            "✓ Baseline complete! Ready for LSTM comparison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Long Short-Term Memory (LSTM) MODEL\n",
        "# ============================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "print(\"Building LSTM Model...\\n\")\n",
        "\n",
        "# Step 1: Create sequences (use past 24 hours to predict next value)\n",
        "print(\"Step 1: Creating sequences...\")\n",
        "lookback = 96  # 24 hours * 4 (15-min intervals)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data[['total_power_kw']])\n",
        "test_scaled = scaler.transform(test_data[['total_power_kw']])\n",
        "\n",
        "def create_sequences(data, lookback):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i+lookback])\n",
        "        y.append(data[i+lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "print(f\"   Training sequences: {X_train.shape}\")\n",
        "print(f\"   Test sequences: {X_test.shape}\")\n",
        "\n",
        "# Step 2: Build LSTM architecture\n",
        "print(\"\\nStep 2: Building LSTM model...\")\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "print(\"   ✓ Model architecture created\")\n",
        "\n",
        "# Step 3: Train model\n",
        "print(\"\\nStep 3: Training LSTM (this takes 5-10 minutes)...\\n\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Is6cfH4Ms2h",
        "outputId": "f0e8f59d-4bb9-42cb-dea1-0db17a8cba21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building LSTM Model...\n",
            "\n",
            "Step 1: Creating sequences...\n",
            "   Training sequences: (6972, 96, 1)\n",
            "   Test sequences: (1671, 96, 1)\n",
            "\n",
            "Step 2: Building LSTM model...\n",
            "   ✓ Model architecture created\n",
            "\n",
            "Step 3: Training LSTM (this takes 5-10 minutes)...\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 0.0102 - mae: 0.0614 - val_loss: 0.0065 - val_mae: 0.0407\n",
            "Epoch 2/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.0082 - mae: 0.0535 - val_loss: 0.0057 - val_mae: 0.0482\n",
            "Epoch 3/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - loss: 0.0076 - mae: 0.0506 - val_loss: 0.0053 - val_mae: 0.0424\n",
            "Epoch 4/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.0066 - mae: 0.0464 - val_loss: 0.0052 - val_mae: 0.0450\n",
            "Epoch 5/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - loss: 0.0078 - mae: 0.0521 - val_loss: 0.0050 - val_mae: 0.0392\n",
            "Epoch 6/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - loss: 0.0071 - mae: 0.0490 - val_loss: 0.0049 - val_mae: 0.0359\n",
            "Epoch 7/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.0070 - mae: 0.0479 - val_loss: 0.0046 - val_mae: 0.0368\n",
            "Epoch 8/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.0068 - mae: 0.0478 - val_loss: 0.0045 - val_mae: 0.0330\n",
            "Epoch 9/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.0060 - mae: 0.0441 - val_loss: 0.0043 - val_mae: 0.0360\n",
            "Epoch 10/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.0060 - mae: 0.0448 - val_loss: 0.0043 - val_mae: 0.0400\n",
            "Epoch 11/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - loss: 0.0066 - mae: 0.0477 - val_loss: 0.0044 - val_mae: 0.0324\n",
            "Epoch 12/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0063 - mae: 0.0445 - val_loss: 0.0042 - val_mae: 0.0367\n",
            "Epoch 13/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - loss: 0.0060 - mae: 0.0445 - val_loss: 0.0044 - val_mae: 0.0327\n",
            "Epoch 14/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - loss: 0.0068 - mae: 0.0469 - val_loss: 0.0042 - val_mae: 0.0348\n",
            "Epoch 15/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - loss: 0.0059 - mae: 0.0434 - val_loss: 0.0043 - val_mae: 0.0333\n",
            "Epoch 16/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - loss: 0.0063 - mae: 0.0452 - val_loss: 0.0042 - val_mae: 0.0340\n",
            "Epoch 17/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - loss: 0.0063 - mae: 0.0446 - val_loss: 0.0043 - val_mae: 0.0389\n",
            "Epoch 18/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 0.0067 - mae: 0.0462 - val_loss: 0.0042 - val_mae: 0.0369\n",
            "Epoch 19/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.0064 - mae: 0.0451 - val_loss: 0.0042 - val_mae: 0.0324\n",
            "Epoch 20/20\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - loss: 0.0061 - mae: 0.0426 - val_loss: 0.0043 - val_mae: 0.0320\n",
            "\n",
            "✓ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Generate predictions\n",
        "print(\"Step 4: Generating predictions...\")\n",
        "y_test_pred_scaled = model.predict(X_test, verbose=0)\n",
        "\n",
        "# Inverse transform\n",
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "y_test_pred = scaler.inverse_transform(y_test_pred_scaled)\n",
        "\n",
        "print(\"✓ Predictions generated!\")\n",
        "\n",
        "# ============================================================\n",
        "# Save the trained model\n",
        "print(\"\\nSaving model + scaler to Google Drive...\")\n",
        "\n",
        "# Save model\n",
        "model.save('/content/drive/MyDrive/lstm_model_summer_UNIVARIATE.h5')\n",
        "\n",
        "# Save scaler params (just like your original method)\n",
        "scaler_params = {\n",
        "    'min': scaler.min_,\n",
        "    'scale': scaler.scale_\n",
        "}\n",
        "\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/scaler_params_summer_UNIVARIATE.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler_params, f)\n",
        "\n",
        "print(\"✓ Model and scaler saved successfully!\")\n",
        "# ============================================================\n",
        "\n",
        "# Step 5: Calculate metrics\n",
        "lstm_rmse = np.sqrt(mean_squared_error(y_test_actual, y_test_pred))\n",
        "lstm_mae = mean_absolute_error(y_test_actual, y_test_pred)\n",
        "lstm_mape = np.mean(np.abs((y_test_actual - y_test_pred) / y_test_actual)) * 100\n",
        "lstm_r2 = r2_score(y_test_actual, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LSTM MODEL RESULTS (Table 2)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"   RMSE: {lstm_rmse:.4f} kW\")\n",
        "print(f\"   MAE:  {lstm_mae:.4f} kW\")\n",
        "print(f\"   MAPE: {lstm_mape:.2f}%\")\n",
        "print(f\"   R²:   {lstm_r2:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Comparison with baseline\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON: LSTM vs BASELINE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Linear Regression: RMSE={baseline_results['RMSE']:.4f}, R²={baseline_results['R2']:.4f}\")\n",
        "print(f\"LSTM:              RMSE={lstm_rmse:.4f}, R²={lstm_r2:.4f}\")\n",
        "print(f\"\\nImprovement:\")\n",
        "print(f\"   RMSE: {((baseline_results['RMSE']-lstm_rmse)/baseline_results['RMSE']*100):.1f}% better\")\n",
        "print(f\"   R²:   {lstm_r2:.4f} (baseline was {baseline_results['R2']:.4f})\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "lstm_results = {\n",
        "    'Model': 'LSTM',\n",
        "    'RMSE': lstm_rmse,\n",
        "    'MAE': lstm_mae,\n",
        "    'MAPE': lstm_mape,\n",
        "    'R2': lstm_r2\n",
        "}\n",
        "\n",
        "print(\"\\n✓ LSTM MODEL COMPLETE! Table 2 ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HozwWkfSUBsR",
        "outputId": "271133ad-8135-4e67-9581-4140c1e788f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: Generating predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Predictions generated!\n",
            "\n",
            "Saving model + scaler to Google Drive...\n",
            "✓ Model and scaler saved successfully!\n",
            "\n",
            "============================================================\n",
            "LSTM MODEL RESULTS (Table 2)\n",
            "============================================================\n",
            "   RMSE: 0.8021 kW\n",
            "   MAE:  0.3930 kW\n",
            "   MAPE: 26.12%\n",
            "   R²:   0.3600\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "COMPARISON: LSTM vs BASELINE\n",
            "============================================================\n",
            "Linear Regression: RMSE=0.9669, R²=0.0625\n",
            "LSTM:              RMSE=0.8021, R²=0.3600\n",
            "\n",
            "Improvement:\n",
            "   RMSE: 17.0% better\n",
            "   R²:   0.3600 (baseline was 0.0625)\n",
            "============================================================\n",
            "\n",
            "✓ LSTM MODEL COMPLETE! Table 2 ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Table 2 results\n",
        "import pandas as pd\n",
        "\n",
        "table_2 = pd.DataFrame([\n",
        "    {\n",
        "        'Model': 'Linear Regression',\n",
        "        'RMSE (kW)': f\"{baseline_results['RMSE']:.4f}\",\n",
        "        'MAE (kW)': f\"{baseline_results['MAE']:.4f}\",\n",
        "        'MAPE (%)': f\"{baseline_results['MAPE']:.2f}\",\n",
        "        'R²': f\"{baseline_results['R2']:.4f}\"\n",
        "    },\n",
        "    {\n",
        "        'Model': 'LSTM',\n",
        "        'RMSE (kW)': f\"{lstm_results['RMSE']:.4f}\",\n",
        "        'MAE (kW)': f\"{lstm_results['MAE']:.4f}\",\n",
        "        'MAPE (%)': f\"{lstm_results['MAPE']:.2f}\",\n",
        "        'R²': f\"{lstm_results['R2']:.4f}\"\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TABLE 2: Load Forecasting Model Performance Comparison\")\n",
        "print(\"=\"*70)\n",
        "print(table_2.to_string(index=False))\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geqJuyKDUKPl",
        "outputId": "dd23cc06-3aa8-4bd3-aee5-08c905c9918b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TABLE 2: Load Forecasting Model Performance Comparison\n",
            "======================================================================\n",
            "            Model RMSE (kW) MAE (kW) MAPE (%)     R²\n",
            "Linear Regression    0.9669   0.6542    58.58 0.0625\n",
            "             LSTM    0.8021   0.3930    26.12 0.3600\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nxf_XJc6Bpk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYuy29dYKNgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}